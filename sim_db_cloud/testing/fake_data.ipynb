{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from random import randint, seed, getrandbits,choices,choice\n",
    "from datetime import datetime,timedelta\n",
    "from numpy import array\n",
    "from pandas import DataFrame,date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_ids(data):\n",
    "    \"\"\"Extrae los ids de la data entregada\n",
    "\n",
    "    Args:\n",
    "        data (list): Lista de diccionarios donde se encuentra la data\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: Arreglo que trae la lista de los ids unicos\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = DataFrame(data)\n",
    "        return df[df.columns[0]].unique()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Falla extrayendo los ids\")\n",
    "        return array(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(start_time,interval,length):\n",
    "    \"\"\"Calcula una serie de tiempo a partir de un tiempo de inicio y el intervalo\n",
    "\n",
    "    Args:\n",
    "        start_time (datetime.datetime): Fecha de inicio de la serie de tiempo\n",
    "        interval (int): Ventana en segundos del intervalo que se utilzara para las muestras\n",
    "\n",
    "    Returns:\n",
    "        list(str): retorna una lista con los valores en str de la serie de tiempo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        end_time = start_time+timedelta(minutes=length)\n",
    "        periods = (end_time-start_time).seconds/interval\n",
    "        timeline = date_range(start_time, periods=periods, freq=str(interval)+'s')\n",
    "        return list(timeline.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Problema calculando la serie de tiempo\")\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prof_timeline(sample_size,top_prof):\n",
    "    \"\"\"Genera valores aleatorios para la linea de tiempo de profundidad.\n",
    "\n",
    "    Args:\n",
    "        sample_size (int): tamaÃ±o de la muestra \n",
    "        top_prof (int): valor maximo de la profundidad\n",
    "\n",
    "    Returns:\n",
    "        list (int): retorna una lista con los valores de profundidad\n",
    "    \"\"\"\n",
    "    init_prof = 0\n",
    "    timeline_prof = [0]\n",
    "    \n",
    "    try:\n",
    "        for i in range(sample_size-1):\n",
    "            #Que empiece a subir una vez pasado el 75% del tiempo de muestra\n",
    "            if i>int(0.75*sample_size):\n",
    "                init_prof-=randint(1,2)\n",
    "                if init_prof<0:\n",
    "                    init_prof=0\n",
    "            #Mientras no llegue al 60% de la prof maxima, seguira bajando        \n",
    "            elif init_prof<0.60*top_prof:\n",
    "                init_prof+=randint(0,2)\n",
    "            #Pasado el 75%, subira o bajara 1 [m]    \n",
    "            else:\n",
    "                init_prof+=1*choice([-1,1])\n",
    "            timeline_prof.append(init_prof)\n",
    "        return timeline_prof\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando los valores de la profundidad\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_supervisor(data_size):\n",
    "    \"\"\"Genera registros falsos para la tabla Supervisor en formato diccionario.\n",
    "\n",
    "    Args:\n",
    "        data_size (int): cantidad de registros a generar.\n",
    "\n",
    "    Returns:\n",
    "        list: lista de diccionarios con los registros nuevos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seed(datetime.now().timestamp())\n",
    "        fake = Faker(\"es_CL\")\n",
    "        new_data = []\n",
    "        for i in range(data_size):\n",
    "            new_data.append(\n",
    "                {\n",
    "                #bigint \n",
    "                \"_id_sup\":randint(0,pow(2,31)),\n",
    "                \"name_sup\":fake.given_name(),\n",
    "                \"email\": fake.safe_email(),\n",
    "                \"password\": hex(getrandbits(128)),\n",
    "                \"company\": fake.company()\n",
    "                }\n",
    "            )\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando registros ficticion para Supervisor\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_buzo(data_size):\n",
    "    \"\"\"Genera registros falsos para la tabla Faenas en formato diccionario.\n",
    "\n",
    "    Args:\n",
    "        data_size (int): cantidad de registros a generar.\n",
    "\n",
    "    Returns:\n",
    "        list: lista de diccionarios con los registros nuevos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seed(datetime.now().timestamp())\n",
    "        fake = Faker(\"es_CL\")\n",
    "        new_data = []\n",
    "        for i in range(data_size):\n",
    "            new_data.append(\n",
    "                {\n",
    "                #bigint \n",
    "                \"_id_buzo\":randint(0,pow(2,31)),\n",
    "                \"name_buzo\":fake.given_name(),\n",
    "                \"company\":fake.company(),\n",
    "                \"imagen\":fake.image_url()\n",
    "                #,id_team: lista de los equipos en los que ha estado/ultimo equipo que estuvo\n",
    "                }\n",
    "            )\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando registros ficticion para Buzo\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_team(data_size,sups_ids,buzos_ids):\n",
    "    \"\"\"Genera registros falsos para la tabla Team en formato diccionario.\n",
    "\n",
    "    Args:\n",
    "        data_size (int): cantidad de registros a generar.\n",
    "        sups_ids (numpy.array): lista con los id existentes de la tabla Supervisor.\n",
    "        buzos_ids (numpy.array): lista con los id existentes de la tabla Buzo.\n",
    "\n",
    "    Returns:\n",
    "        list: lista de diccionarios con los registros nuevos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seed(datetime.now().timestamp())\n",
    "        fake = Faker(\"es_CL\")\n",
    "        new_data = []\n",
    "        for i in range(data_size):\n",
    "            new_data.append(\n",
    "                {\n",
    "                #bigint \n",
    "                \"_id_team\":randint(0,pow(2,31)),\n",
    "                \"id_sup\":sups_ids[randint(0,len(sups_ids)-1)],\n",
    "                \"id_buzo\":choices(buzos_ids,k=randint(3,10))\n",
    "                }\n",
    "            )\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando registros ficticion para Team\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_faena(data_size,magnitud,ids_teams):\n",
    "    \"\"\"Genera registros falsos para la tabla Faena en formato diccionario.\n",
    "\n",
    "    Args:\n",
    "        data_size (int): cantidad de registros a generar.\n",
    "        magnitud (int): valor entero que representa la magnitud de los datos a generar.\n",
    "                        Se usa para aumentar o disminuir la ventana de tiempo para elegir\n",
    "                        un start_time y end_time\n",
    "        ids_teams (numpy.array): ids de los registros en Team agregados\n",
    "\n",
    "    Returns:\n",
    "        list: lista de diccionarios con los registros nuevos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        seed(datetime.now().timestamp())\n",
    "        fake = Faker(\"es_CL\")\n",
    "        new_data = []\n",
    "        for i in range(data_size):\n",
    "            start_time = fake.unix_time(datetime.today()- timedelta(days=7*magnitud),datetime.today() - timedelta(days=14*magnitud))\n",
    "            end_time = fake.unix_time(datetime.fromtimestamp(start_time) + timedelta(days=14) ,datetime.fromtimestamp(start_time) + timedelta(days=7)  )\n",
    "            new_data.append(\n",
    "                {\n",
    "                #bigint \n",
    "                \"_id_faena\":randint(0,pow(2,31)),\n",
    "                \"id_team\": ids_teams[randint(0,len(ids_teams)-1)],\n",
    "                \"start_time\":start_time,\n",
    "                \"end_time\":end_time\n",
    "                }\n",
    "            )\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando registros ficticion para Faena\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_inmersion(data_size,buzos_ids,magnitud):\n",
    "    \"\"\"Genera registros falsos para la tabla Team en formato diccionario.\n",
    "\n",
    "    Args:\n",
    "        data_size (int): cantidad de registros a generar.\n",
    "        buzos_ids (numpy.array): lista con los id existentes de la tabla Buzo.\n",
    "\n",
    "    Returns:\n",
    "        list: lista de diccionarios con los registros nuevos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seed(datetime.now().timestamp())\n",
    "        fake = Faker(\"es_CL\")\n",
    "        new_data = []\n",
    "        for i in range(data_size):\n",
    "            date = fake.unix_time(datetime.today(),datetime.today()- timedelta(days=14*magnitud))\n",
    "            timeline_time = get_timeline(datetime.fromtimestamp(date),15,80)\n",
    "            timeline_prof = get_prof_timeline(len(timeline_time),40)\n",
    "            new_data.append(\n",
    "                {\n",
    "                #bigint \n",
    "                \"_id_inmersion\":randint(0,pow(2,31)),\n",
    "                \"id_buzo\":buzos_ids[randint(0,len(buzos_ids)-1)],\n",
    "                \"date\":date,\n",
    "                #\"timeline_inmer\":0,\n",
    "                \"timeline_time\":timeline_time,\n",
    "                \"timeline_prof\":timeline_prof\n",
    "                }\n",
    "            )\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando registros ficticion para Inmersion\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_alarm(data_size,buzos_ids,inmersions_ids):\n",
    "    \"\"\"Genera registros falsos para la tabla Team en formato diccionario.\n",
    "\n",
    "    Args:\n",
    "        data_size (int): cantidad de registros a generar.\n",
    "        buzos_ids (numpy.array): lista con los id existentes de la tabla Buzo.\n",
    "        inmersions_ids (numpy.array): lista con los id existentes de la tabla Inmersion.\n",
    "\n",
    "    Returns:\n",
    "        list: lista de diccionarios con los registros nuevos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        seed(datetime.now().timestamp())\n",
    "        fake = Faker(\"es_CL\")\n",
    "        new_data = []\n",
    "        for i in range(data_size):\n",
    "            new_data.append(\n",
    "                {\n",
    "                #bigint \n",
    "                \"_id_alarm\":randint(0,pow(2,31)),\n",
    "                \"id_buzo\":buzos_ids[randint(0,len(buzos_ids)-1)],\n",
    "                \"id_inmersion\":inmersions_ids[randint(0,len(inmersions_ids)-1)],\n",
    "                \"type_alarm\":f\"Alarma {randint(1,5)}\",\n",
    "                \"time_total\":randint(20,40),\n",
    "                \"level_nitro\":randint(40,100)/100,\n",
    "                \"level_prof\":randint(30,50)\n",
    "                }\n",
    "            )\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        print(\"Hint: Error creando registros ficticion para Inmersion\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id_inmersion': 132657711,\n",
       "  'id_buzo': 1,\n",
       "  'date': 1695730987,\n",
       "  'timeline_time': ['26/09/2023 09:23:07',\n",
       "   '26/09/2023 09:23:22',\n",
       "   '26/09/2023 09:23:37',\n",
       "   '26/09/2023 09:23:52',\n",
       "   '26/09/2023 09:24:07',\n",
       "   '26/09/2023 09:24:22',\n",
       "   '26/09/2023 09:24:37',\n",
       "   '26/09/2023 09:24:52',\n",
       "   '26/09/2023 09:25:07',\n",
       "   '26/09/2023 09:25:22',\n",
       "   '26/09/2023 09:25:37',\n",
       "   '26/09/2023 09:25:52',\n",
       "   '26/09/2023 09:26:07',\n",
       "   '26/09/2023 09:26:22',\n",
       "   '26/09/2023 09:26:37',\n",
       "   '26/09/2023 09:26:52',\n",
       "   '26/09/2023 09:27:07',\n",
       "   '26/09/2023 09:27:22',\n",
       "   '26/09/2023 09:27:37',\n",
       "   '26/09/2023 09:27:52',\n",
       "   '26/09/2023 09:28:07',\n",
       "   '26/09/2023 09:28:22',\n",
       "   '26/09/2023 09:28:37',\n",
       "   '26/09/2023 09:28:52',\n",
       "   '26/09/2023 09:29:07',\n",
       "   '26/09/2023 09:29:22',\n",
       "   '26/09/2023 09:29:37',\n",
       "   '26/09/2023 09:29:52',\n",
       "   '26/09/2023 09:30:07',\n",
       "   '26/09/2023 09:30:22',\n",
       "   '26/09/2023 09:30:37',\n",
       "   '26/09/2023 09:30:52',\n",
       "   '26/09/2023 09:31:07',\n",
       "   '26/09/2023 09:31:22',\n",
       "   '26/09/2023 09:31:37',\n",
       "   '26/09/2023 09:31:52',\n",
       "   '26/09/2023 09:32:07',\n",
       "   '26/09/2023 09:32:22',\n",
       "   '26/09/2023 09:32:37',\n",
       "   '26/09/2023 09:32:52',\n",
       "   '26/09/2023 09:33:07',\n",
       "   '26/09/2023 09:33:22',\n",
       "   '26/09/2023 09:33:37',\n",
       "   '26/09/2023 09:33:52',\n",
       "   '26/09/2023 09:34:07',\n",
       "   '26/09/2023 09:34:22',\n",
       "   '26/09/2023 09:34:37',\n",
       "   '26/09/2023 09:34:52',\n",
       "   '26/09/2023 09:35:07',\n",
       "   '26/09/2023 09:35:22',\n",
       "   '26/09/2023 09:35:37',\n",
       "   '26/09/2023 09:35:52',\n",
       "   '26/09/2023 09:36:07',\n",
       "   '26/09/2023 09:36:22',\n",
       "   '26/09/2023 09:36:37',\n",
       "   '26/09/2023 09:36:52',\n",
       "   '26/09/2023 09:37:07',\n",
       "   '26/09/2023 09:37:22',\n",
       "   '26/09/2023 09:37:37',\n",
       "   '26/09/2023 09:37:52',\n",
       "   '26/09/2023 09:38:07',\n",
       "   '26/09/2023 09:38:22',\n",
       "   '26/09/2023 09:38:37',\n",
       "   '26/09/2023 09:38:52',\n",
       "   '26/09/2023 09:39:07',\n",
       "   '26/09/2023 09:39:22',\n",
       "   '26/09/2023 09:39:37',\n",
       "   '26/09/2023 09:39:52',\n",
       "   '26/09/2023 09:40:07',\n",
       "   '26/09/2023 09:40:22',\n",
       "   '26/09/2023 09:40:37',\n",
       "   '26/09/2023 09:40:52',\n",
       "   '26/09/2023 09:41:07',\n",
       "   '26/09/2023 09:41:22',\n",
       "   '26/09/2023 09:41:37',\n",
       "   '26/09/2023 09:41:52',\n",
       "   '26/09/2023 09:42:07',\n",
       "   '26/09/2023 09:42:22',\n",
       "   '26/09/2023 09:42:37',\n",
       "   '26/09/2023 09:42:52',\n",
       "   '26/09/2023 09:43:07',\n",
       "   '26/09/2023 09:43:22',\n",
       "   '26/09/2023 09:43:37',\n",
       "   '26/09/2023 09:43:52',\n",
       "   '26/09/2023 09:44:07',\n",
       "   '26/09/2023 09:44:22',\n",
       "   '26/09/2023 09:44:37',\n",
       "   '26/09/2023 09:44:52',\n",
       "   '26/09/2023 09:45:07',\n",
       "   '26/09/2023 09:45:22',\n",
       "   '26/09/2023 09:45:37',\n",
       "   '26/09/2023 09:45:52',\n",
       "   '26/09/2023 09:46:07',\n",
       "   '26/09/2023 09:46:22',\n",
       "   '26/09/2023 09:46:37',\n",
       "   '26/09/2023 09:46:52',\n",
       "   '26/09/2023 09:47:07',\n",
       "   '26/09/2023 09:47:22',\n",
       "   '26/09/2023 09:47:37',\n",
       "   '26/09/2023 09:47:52',\n",
       "   '26/09/2023 09:48:07',\n",
       "   '26/09/2023 09:48:22',\n",
       "   '26/09/2023 09:48:37',\n",
       "   '26/09/2023 09:48:52',\n",
       "   '26/09/2023 09:49:07',\n",
       "   '26/09/2023 09:49:22',\n",
       "   '26/09/2023 09:49:37',\n",
       "   '26/09/2023 09:49:52',\n",
       "   '26/09/2023 09:50:07',\n",
       "   '26/09/2023 09:50:22',\n",
       "   '26/09/2023 09:50:37',\n",
       "   '26/09/2023 09:50:52',\n",
       "   '26/09/2023 09:51:07',\n",
       "   '26/09/2023 09:51:22',\n",
       "   '26/09/2023 09:51:37',\n",
       "   '26/09/2023 09:51:52',\n",
       "   '26/09/2023 09:52:07',\n",
       "   '26/09/2023 09:52:22',\n",
       "   '26/09/2023 09:52:37',\n",
       "   '26/09/2023 09:52:52',\n",
       "   '26/09/2023 09:53:07',\n",
       "   '26/09/2023 09:53:22',\n",
       "   '26/09/2023 09:53:37',\n",
       "   '26/09/2023 09:53:52',\n",
       "   '26/09/2023 09:54:07',\n",
       "   '26/09/2023 09:54:22',\n",
       "   '26/09/2023 09:54:37',\n",
       "   '26/09/2023 09:54:52',\n",
       "   '26/09/2023 09:55:07',\n",
       "   '26/09/2023 09:55:22',\n",
       "   '26/09/2023 09:55:37',\n",
       "   '26/09/2023 09:55:52',\n",
       "   '26/09/2023 09:56:07',\n",
       "   '26/09/2023 09:56:22',\n",
       "   '26/09/2023 09:56:37',\n",
       "   '26/09/2023 09:56:52',\n",
       "   '26/09/2023 09:57:07',\n",
       "   '26/09/2023 09:57:22',\n",
       "   '26/09/2023 09:57:37',\n",
       "   '26/09/2023 09:57:52',\n",
       "   '26/09/2023 09:58:07',\n",
       "   '26/09/2023 09:58:22',\n",
       "   '26/09/2023 09:58:37',\n",
       "   '26/09/2023 09:58:52',\n",
       "   '26/09/2023 09:59:07',\n",
       "   '26/09/2023 09:59:22',\n",
       "   '26/09/2023 09:59:37',\n",
       "   '26/09/2023 09:59:52',\n",
       "   '26/09/2023 10:00:07',\n",
       "   '26/09/2023 10:00:22',\n",
       "   '26/09/2023 10:00:37',\n",
       "   '26/09/2023 10:00:52',\n",
       "   '26/09/2023 10:01:07',\n",
       "   '26/09/2023 10:01:22',\n",
       "   '26/09/2023 10:01:37',\n",
       "   '26/09/2023 10:01:52',\n",
       "   '26/09/2023 10:02:07',\n",
       "   '26/09/2023 10:02:22',\n",
       "   '26/09/2023 10:02:37',\n",
       "   '26/09/2023 10:02:52',\n",
       "   '26/09/2023 10:03:07',\n",
       "   '26/09/2023 10:03:22',\n",
       "   '26/09/2023 10:03:37',\n",
       "   '26/09/2023 10:03:52',\n",
       "   '26/09/2023 10:04:07',\n",
       "   '26/09/2023 10:04:22',\n",
       "   '26/09/2023 10:04:37',\n",
       "   '26/09/2023 10:04:52',\n",
       "   '26/09/2023 10:05:07',\n",
       "   '26/09/2023 10:05:22',\n",
       "   '26/09/2023 10:05:37',\n",
       "   '26/09/2023 10:05:52',\n",
       "   '26/09/2023 10:06:07',\n",
       "   '26/09/2023 10:06:22',\n",
       "   '26/09/2023 10:06:37',\n",
       "   '26/09/2023 10:06:52',\n",
       "   '26/09/2023 10:07:07',\n",
       "   '26/09/2023 10:07:22',\n",
       "   '26/09/2023 10:07:37',\n",
       "   '26/09/2023 10:07:52',\n",
       "   '26/09/2023 10:08:07',\n",
       "   '26/09/2023 10:08:22',\n",
       "   '26/09/2023 10:08:37',\n",
       "   '26/09/2023 10:08:52',\n",
       "   '26/09/2023 10:09:07',\n",
       "   '26/09/2023 10:09:22',\n",
       "   '26/09/2023 10:09:37',\n",
       "   '26/09/2023 10:09:52',\n",
       "   '26/09/2023 10:10:07',\n",
       "   '26/09/2023 10:10:22',\n",
       "   '26/09/2023 10:10:37',\n",
       "   '26/09/2023 10:10:52',\n",
       "   '26/09/2023 10:11:07',\n",
       "   '26/09/2023 10:11:22',\n",
       "   '26/09/2023 10:11:37',\n",
       "   '26/09/2023 10:11:52',\n",
       "   '26/09/2023 10:12:07',\n",
       "   '26/09/2023 10:12:22',\n",
       "   '26/09/2023 10:12:37',\n",
       "   '26/09/2023 10:12:52',\n",
       "   '26/09/2023 10:13:07',\n",
       "   '26/09/2023 10:13:22',\n",
       "   '26/09/2023 10:13:37',\n",
       "   '26/09/2023 10:13:52',\n",
       "   '26/09/2023 10:14:07',\n",
       "   '26/09/2023 10:14:22',\n",
       "   '26/09/2023 10:14:37',\n",
       "   '26/09/2023 10:14:52',\n",
       "   '26/09/2023 10:15:07',\n",
       "   '26/09/2023 10:15:22',\n",
       "   '26/09/2023 10:15:37',\n",
       "   '26/09/2023 10:15:52',\n",
       "   '26/09/2023 10:16:07',\n",
       "   '26/09/2023 10:16:22',\n",
       "   '26/09/2023 10:16:37',\n",
       "   '26/09/2023 10:16:52',\n",
       "   '26/09/2023 10:17:07',\n",
       "   '26/09/2023 10:17:22',\n",
       "   '26/09/2023 10:17:37',\n",
       "   '26/09/2023 10:17:52',\n",
       "   '26/09/2023 10:18:07',\n",
       "   '26/09/2023 10:18:22',\n",
       "   '26/09/2023 10:18:37',\n",
       "   '26/09/2023 10:18:52',\n",
       "   '26/09/2023 10:19:07',\n",
       "   '26/09/2023 10:19:22',\n",
       "   '26/09/2023 10:19:37',\n",
       "   '26/09/2023 10:19:52',\n",
       "   '26/09/2023 10:20:07',\n",
       "   '26/09/2023 10:20:22',\n",
       "   '26/09/2023 10:20:37',\n",
       "   '26/09/2023 10:20:52',\n",
       "   '26/09/2023 10:21:07',\n",
       "   '26/09/2023 10:21:22',\n",
       "   '26/09/2023 10:21:37',\n",
       "   '26/09/2023 10:21:52',\n",
       "   '26/09/2023 10:22:07',\n",
       "   '26/09/2023 10:22:22',\n",
       "   '26/09/2023 10:22:37',\n",
       "   '26/09/2023 10:22:52',\n",
       "   '26/09/2023 10:23:07',\n",
       "   '26/09/2023 10:23:22',\n",
       "   '26/09/2023 10:23:37',\n",
       "   '26/09/2023 10:23:52',\n",
       "   '26/09/2023 10:24:07',\n",
       "   '26/09/2023 10:24:22',\n",
       "   '26/09/2023 10:24:37',\n",
       "   '26/09/2023 10:24:52',\n",
       "   '26/09/2023 10:25:07',\n",
       "   '26/09/2023 10:25:22',\n",
       "   '26/09/2023 10:25:37',\n",
       "   '26/09/2023 10:25:52',\n",
       "   '26/09/2023 10:26:07',\n",
       "   '26/09/2023 10:26:22',\n",
       "   '26/09/2023 10:26:37',\n",
       "   '26/09/2023 10:26:52',\n",
       "   '26/09/2023 10:27:07',\n",
       "   '26/09/2023 10:27:22',\n",
       "   '26/09/2023 10:27:37',\n",
       "   '26/09/2023 10:27:52',\n",
       "   '26/09/2023 10:28:07',\n",
       "   '26/09/2023 10:28:22',\n",
       "   '26/09/2023 10:28:37',\n",
       "   '26/09/2023 10:28:52',\n",
       "   '26/09/2023 10:29:07',\n",
       "   '26/09/2023 10:29:22',\n",
       "   '26/09/2023 10:29:37',\n",
       "   '26/09/2023 10:29:52',\n",
       "   '26/09/2023 10:30:07',\n",
       "   '26/09/2023 10:30:22',\n",
       "   '26/09/2023 10:30:37',\n",
       "   '26/09/2023 10:30:52',\n",
       "   '26/09/2023 10:31:07',\n",
       "   '26/09/2023 10:31:22',\n",
       "   '26/09/2023 10:31:37',\n",
       "   '26/09/2023 10:31:52',\n",
       "   '26/09/2023 10:32:07',\n",
       "   '26/09/2023 10:32:22',\n",
       "   '26/09/2023 10:32:37',\n",
       "   '26/09/2023 10:32:52',\n",
       "   '26/09/2023 10:33:07',\n",
       "   '26/09/2023 10:33:22',\n",
       "   '26/09/2023 10:33:37',\n",
       "   '26/09/2023 10:33:52',\n",
       "   '26/09/2023 10:34:07',\n",
       "   '26/09/2023 10:34:22',\n",
       "   '26/09/2023 10:34:37',\n",
       "   '26/09/2023 10:34:52',\n",
       "   '26/09/2023 10:35:07',\n",
       "   '26/09/2023 10:35:22',\n",
       "   '26/09/2023 10:35:37',\n",
       "   '26/09/2023 10:35:52',\n",
       "   '26/09/2023 10:36:07',\n",
       "   '26/09/2023 10:36:22',\n",
       "   '26/09/2023 10:36:37',\n",
       "   '26/09/2023 10:36:52',\n",
       "   '26/09/2023 10:37:07',\n",
       "   '26/09/2023 10:37:22',\n",
       "   '26/09/2023 10:37:37',\n",
       "   '26/09/2023 10:37:52',\n",
       "   '26/09/2023 10:38:07',\n",
       "   '26/09/2023 10:38:22',\n",
       "   '26/09/2023 10:38:37',\n",
       "   '26/09/2023 10:38:52',\n",
       "   '26/09/2023 10:39:07',\n",
       "   '26/09/2023 10:39:22',\n",
       "   '26/09/2023 10:39:37',\n",
       "   '26/09/2023 10:39:52',\n",
       "   '26/09/2023 10:40:07',\n",
       "   '26/09/2023 10:40:22',\n",
       "   '26/09/2023 10:40:37',\n",
       "   '26/09/2023 10:40:52',\n",
       "   '26/09/2023 10:41:07',\n",
       "   '26/09/2023 10:41:22',\n",
       "   '26/09/2023 10:41:37',\n",
       "   '26/09/2023 10:41:52',\n",
       "   '26/09/2023 10:42:07',\n",
       "   '26/09/2023 10:42:22',\n",
       "   '26/09/2023 10:42:37',\n",
       "   '26/09/2023 10:42:52'],\n",
       "  'timeline_prof': [0,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   8,\n",
       "   10,\n",
       "   12,\n",
       "   13,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   17,\n",
       "   19,\n",
       "   19,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   23,\n",
       "   24,\n",
       "   23,\n",
       "   23,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   27,\n",
       "   28,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   27,\n",
       "   28,\n",
       "   27,\n",
       "   28,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   23,\n",
       "   24,\n",
       "   23,\n",
       "   25,\n",
       "   24,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   31,\n",
       "   32,\n",
       "   31,\n",
       "   32,\n",
       "   31,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   33,\n",
       "   32,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   32,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   37,\n",
       "   36,\n",
       "   35,\n",
       "   36,\n",
       "   35,\n",
       "   34,\n",
       "   35,\n",
       "   34,\n",
       "   33,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   34,\n",
       "   35,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   37,\n",
       "   36,\n",
       "   35,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   35,\n",
       "   34,\n",
       "   33,\n",
       "   32,\n",
       "   33,\n",
       "   32,\n",
       "   31,\n",
       "   30,\n",
       "   29,\n",
       "   28,\n",
       "   27,\n",
       "   28,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   27,\n",
       "   26,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   23,\n",
       "   23,\n",
       "   23,\n",
       "   25,\n",
       "   24,\n",
       "   23,\n",
       "   24,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   27,\n",
       "   25,\n",
       "   23,\n",
       "   21,\n",
       "   19,\n",
       "   17,\n",
       "   16,\n",
       "   14,\n",
       "   12,\n",
       "   11,\n",
       "   10,\n",
       "   8,\n",
       "   6,\n",
       "   5,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inmersion = fake_inmersion(1,[1,2,3],1)\n",
    "inmersion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
